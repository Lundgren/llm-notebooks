{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31fd2f8e",
   "metadata": {},
   "source": [
    "# Playing with Temperature and Top-p in Open AI's API\n",
    "\n",
    "This Jupyter Notebook can be used to play with Open AI's logprob values, and is an addition to the blog post [Playing with Temperature and Top-p in Open AI's API](https://lundgren.io/posts/playing-with-temperature-and-top-p-in-open-ais-api/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03904a02-17f5-4df5-bc60-eb8ce20c686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Either set this to a valid Open AI API key or make sure one is set in the .env file\n",
    "open_ai_api_key = None\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    if open_ai_api_key:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = open_ai_api_key\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"OpenAI API key not found. Please set the OPENAI_API_KEY environment variable or provide a valid API key.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ce7aa",
   "metadata": {},
   "source": [
    "Set `logprobs` to `True`, and `top_logprobs` to the amount of probabilities you want (between 1 and 20). Optionally, remove `max_tokens=1` to get more tokens. That will require an update to the rest of the code as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387b0651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_logprobs(prompt, model=\"gpt-4o\"):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        logprobs=True,\n",
    "        top_logprobs=10,\n",
    "        max_tokens=1,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].logprobs.content[0].top_logprobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778dea2",
   "metadata": {},
   "source": [
    "This function will apply Temperature and Top-p filtering to the raw probabilities we get from `fetch_logprobs`, and return a Pandas data frame that can be inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1018cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_temperature_top_p(logprobs, temperature=1.0, top_p=1.0):\n",
    "    original_probs = {}\n",
    "    temperature_probs = {}\n",
    "\n",
    "    # 1. Convert logprobs to probabilities and apply Temperature scaling\n",
    "    for obj in logprobs:\n",
    "        original_probs[obj.token] = math.exp(obj.logprob)\n",
    "        temperature_probs[obj.token] = math.exp(obj.logprob / temperature)\n",
    "\n",
    "    # 2. Normalize temperature-scaled probabilities to sum to 1\n",
    "    total_prob = sum(temperature_probs.values())\n",
    "    normalized_temperature_probs = {\n",
    "        k: v / total_prob for k, v in temperature_probs.items()\n",
    "    }\n",
    "\n",
    "    # 3. Apply Top-p (nucleus) filtering\n",
    "    cumulative_prob = 0\n",
    "    top_p_filtered_probs = {}\n",
    "    top_p_filter_status = {}\n",
    "    cumulative_probs = {}\n",
    "\n",
    "    for token, prob in normalized_temperature_probs.items():\n",
    "        if cumulative_prob <= top_p:\n",
    "            top_p_filtered_probs[token] = prob\n",
    "            top_p_filter_status[token] = True\n",
    "        else:\n",
    "            top_p_filtered_probs[token] = 0\n",
    "            top_p_filter_status[token] = False\n",
    "\n",
    "        cumulative_prob += prob\n",
    "        cumulative_probs[token] = cumulative_prob\n",
    "\n",
    "    # 4. Re-normalize probabilities of the tokens that passed the Top-p filter\n",
    "    total_prob = sum(top_p_filtered_probs.values())\n",
    "    final_probs = {\n",
    "        k: v / total_prob if v > 0 else 0 for k, v in top_p_filtered_probs.items()\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"Token\": normalized_temperature_probs.keys(),\n",
    "            \"Original Probability\": original_probs.values(),\n",
    "            \"After Temperature\": normalized_temperature_probs.values(),\n",
    "            \"Cumulative Probability\": cumulative_probs.values(),\n",
    "            \"Top-p Status\": top_p_filter_status.values(),\n",
    "            \"Final Probability\": final_probs.values(),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d50856c",
   "metadata": {},
   "source": [
    "Finally, alter the prompt and the scenarios to see the different probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b99b17-be4b-445c-b096-fe2751b9571e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1: Temperature=0.2, Top_p=0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Original Probability</th>\n",
       "      <th>After Temperature</th>\n",
       "      <th>Cumulative Probability</th>\n",
       "      <th>Top-p Status</th>\n",
       "      <th>Final Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lazy</td>\n",
       "      <td>0.943006</td>\n",
       "      <td>9.999997e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>3.059023e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sorry</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>3.978958e-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>6.305110e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lazy</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>1.806444e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>1.482820e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>...</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>4.248358e-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>4.248358e-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>1.217175e-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>1.217175e-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token  Original Probability  After Temperature  Cumulative Probability  \\\n",
       "0   lazy              0.943006       9.999997e-01                     1.0   \n",
       "1    The              0.046950       3.059023e-07                     1.0   \n",
       "2  Sorry              0.004948       3.978958e-12                     1.0   \n",
       "3    I'm              0.000860       6.305110e-16                     1.0   \n",
       "4   Lazy              0.000670       1.806444e-16                     1.0   \n",
       "5      l              0.000406       1.482820e-17                     1.0   \n",
       "6    ...              0.000316       4.248358e-18                     1.0   \n",
       "7    the              0.000316       4.248358e-18                     1.0   \n",
       "8      \"              0.000246       1.217175e-18                     1.0   \n",
       "9   What              0.000246       1.217175e-18                     1.0   \n",
       "\n",
       "   Top-p Status  Final Probability  \n",
       "0          True                1.0  \n",
       "1         False                0.0  \n",
       "2         False                0.0  \n",
       "3         False                0.0  \n",
       "4         False                0.0  \n",
       "5         False                0.0  \n",
       "6         False                0.0  \n",
       "7         False                0.0  \n",
       "8         False                0.0  \n",
       "9         False                0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario 2: Temperature=1.5, Top_p=0.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Original Probability</th>\n",
       "      <th>After Temperature</th>\n",
       "      <th>Cumulative Probability</th>\n",
       "      <th>Top-p Status</th>\n",
       "      <th>Final Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lazy</td>\n",
       "      <td>0.943006</td>\n",
       "      <td>0.828892</td>\n",
       "      <td>0.828892</td>\n",
       "      <td>True</td>\n",
       "      <td>0.857977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>0.112178</td>\n",
       "      <td>0.941071</td>\n",
       "      <td>True</td>\n",
       "      <td>0.116115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sorry</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.025030</td>\n",
       "      <td>0.966101</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.973896</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lazy</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.980494</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.985221</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>...</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.989223</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.993225</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.996613</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token  Original Probability  After Temperature  Cumulative Probability  \\\n",
       "0   lazy              0.943006           0.828892                0.828892   \n",
       "1    The              0.046950           0.112178                0.941071   \n",
       "2  Sorry              0.004948           0.025030                0.966101   \n",
       "3    I'm              0.000860           0.007795                0.973896   \n",
       "4   Lazy              0.000670           0.006598                0.980494   \n",
       "5      l              0.000406           0.004728                0.985221   \n",
       "6    ...              0.000316           0.004002                0.989223   \n",
       "7    the              0.000316           0.004002                0.993225   \n",
       "8      \"              0.000246           0.003387                0.996613   \n",
       "9   What              0.000246           0.003387                1.000000   \n",
       "\n",
       "   Top-p Status  Final Probability  \n",
       "0          True           0.857977  \n",
       "1          True           0.116115  \n",
       "2          True           0.025909  \n",
       "3         False           0.000000  \n",
       "4         False           0.000000  \n",
       "5         False           0.000000  \n",
       "6         False           0.000000  \n",
       "7         False           0.000000  \n",
       "8         False           0.000000  \n",
       "9         False           0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"The quick brown fox jumps over the\"\n",
    "logprobs = fetch_logprobs(prompt)\n",
    "\n",
    "\n",
    "print(\"Scenario 1: Temperature=0.2, Top_p=0.5\")\n",
    "df1 = apply_temperature_top_p(logprobs, temperature=0.2, top_p=0.5)\n",
    "display(df1)\n",
    "\n",
    "\n",
    "print(\"\\nScenario 2: Temperature=1.5, Top_p=0.95\")\n",
    "df2 = apply_temperature_top_p(logprobs, temperature=1.5, top_p=0.95)\n",
    "display(df2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
